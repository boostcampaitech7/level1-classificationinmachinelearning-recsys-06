{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\com\\Documents\\GitHub\\level1-classificationinmachinelearning-recsys-06\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List, Dict\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import plotly.express as px\n",
    "\n",
    "# Code 경로 추가\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"\"))))\n",
    "print(sys.path[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\com\\AppData\\Local\\Temp\\ipykernel_7140\\3026538581.py:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  data_path: str = \"..\\..\\data\"\n"
     ]
    }
   ],
   "source": [
    "# 파일 호출\n",
    "data_path: str = \"..\\..\\data\"\n",
    "## raw.csv가 없는 경우 실행\n",
    "# from Code.dataset.merge_all import merge_all\n",
    "# df = merge_all(data_path)\n",
    "data: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"raw.csv\"))\n",
    "submission_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\"))  # ID, target 열만 가진 데이터 미리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns.tolist()\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dict: Dict[str, str] = {\n",
    "    \"ID\": \"ID\",\n",
    "    \"target\": \"target\",\n",
    "    \"_type\": \"_type\",\n",
    "    \"hourly_market-data_coinbase-premium-index_coinbase_premium_gap\": \"premium_gap\",\n",
    "    'hourly_market-data_coinbase-premium-index_coinbase_premium_index': \"premium_index\",\n",
    "    'hourly_market-data_funding-rates_all_exchange_funding_rates': \"funding_rates\",\n",
    "    'hourly_market-data_liquidations_all_exchange_all_symbol_long_liquidations': \"long_liquidations\",\n",
    "    'hourly_market-data_liquidations_all_exchange_all_symbol_short_liquidations': \"short_liquidations\",\n",
    "    'hourly_market-data_liquidations_all_exchange_all_symbol_long_liquidations_usd': \"long_liquidations_usd\",\n",
    "    'hourly_market-data_liquidations_all_exchange_all_symbol_short_liquidations_usd': \"short_liquidations_usd\",\n",
    "    'hourly_market-data_open-interest_all_exchange_all_symbol_open_interest': \"all_symbol_open_interest\",\n",
    "    'hourly_market-data_price-ohlcv_all_exchange_spot_btc_usd_close': \"close\",\n",
    "    'hourly_market-data_price-ohlcv_all_exchange_spot_btc_usd_volume':'volume',\n",
    "    'hourly_market-data_taker-buy-sell-stats_all_exchange_taker_buy_volume': 'buy_volume',\n",
    "    'hourly_market-data_taker-buy-sell-stats_all_exchange_taker_sell_volume':'sell_volume',\n",
    "    'hourly_market-data_taker-buy-sell-stats_all_exchange_taker_buy_ratio':'buy_ratio',\n",
    "    'hourly_market-data_taker-buy-sell-stats_all_exchange_taker_sell_ratio':'sell_ratio',\n",
    "    'hourly_market-data_taker-buy-sell-stats_all_exchange_taker_buy_sell_ratio': 'buy_sell_ratio',\n",
    "    'hourly_network-data_addresses-count_addresses_count_active':'count_active',\n",
    "    'hourly_network-data_addresses-count_addresses_count_sender':'count_sender',\n",
    "    'hourly_network-data_addresses-count_addresses_count_receiver':'count_receiver',\n",
    "    'hourly_network-data_block-bytes_block_bytes':'block_bytes',\n",
    "    'hourly_network-data_block-count_block_count':'block_count',\n",
    "    'hourly_network-data_block-interval_block_interval':'block_interval',\n",
    "    'hourly_network-data_blockreward_blockreward':'blockreward',\n",
    "    'hourly_network-data_blockreward_blockreward_usd':'blockreward_usd',\n",
    "    'hourly_network-data_difficulty_difficulty':'difficulty',\n",
    "    'hourly_network-data_fees-transaction_fees_transaction_mean':'transaction_mean',\n",
    "    'hourly_network-data_fees-transaction_fees_transaction_mean_usd':'transaction_mean_usd',\n",
    "    'hourly_network-data_fees-transaction_fees_transaction_median':'transaction_median',\n",
    "    'hourly_network-data_fees-transaction_fees_transaction_median_usd':'transaction_median_usd',\n",
    "    'hourly_network-data_fees_fees_block_mean':'block_mean',\n",
    "    'hourly_network-data_fees_fees_block_mean_usd':'block_mean_usd',\n",
    "    'hourly_network-data_fees_fees_total':'fees_total',\n",
    "    'hourly_network-data_fees_fees_total_usd':\"fees_total_usd\",\n",
    "    'hourly_network-data_fees_fees_reward_percent':'fees_reward_percent',\n",
    "    'hourly_network-data_hashrate_hashrate':'hashrate',\n",
    "    'hourly_network-data_supply_supply_total':'supply_total',\n",
    "    'hourly_network-data_supply_supply_new':'supply_new',\n",
    "    'hourly_network-data_tokens-transferred_tokens_transferred_total': 'tokens_transferred_total',\n",
    "    'hourly_network-data_tokens-transferred_tokens_transferred_mean':'tokens_transferred_mean',\n",
    "    'hourly_network-data_tokens-transferred_tokens_transferred_median':'tokens_transferred_median',\n",
    "    'hourly_network-data_transactions-count_transactions_count_total':'transactions_count_total',\n",
    "    'hourly_network-data_transactions-count_transactions_count_mean':'transactions_count_mean',\n",
    "    'hourly_network-data_utxo-count_utxo_count':'utxo_count',\n",
    "    'hourly_network-data_velocity_velocity_supply_total':'velocity_supply_total'\n",
    "\n",
    "}\n",
    "df = data[cols_dict.keys()].rename(cols_dict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('features_select_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시차(Lag) 특성을 생성할 컬럼 리스트 정의\n",
    "columns_to_lag = [\n",
    "    'premium_gap',\n",
    "    'premium_index',\n",
    "    'funding_rates',\n",
    "    'all_symbol_open_interest',\n",
    "    'close',\n",
    "    'volume',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시차 (Lag) 특성 생성 함수 정의\n",
    "def create_lag_features(df, columns, max_lag):\n",
    "    df = df.copy()\n",
    "    for col in columns:\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            df[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\com\\Documents\\GitHub\\level1-classificationinmachinelearning-recsys-06\\EDA\\백우성\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\com\\AppData\\Local\\Temp\\ipykernel_7140\\3668511730.py:3: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  sys.path.append('..\\Code\\pre_procecss')\n"
     ]
    }
   ],
   "source": [
    "#from preprocessor import PreProcessor\n",
    "print(os.getcwd())\n",
    "sys.path.append('..\\Code\\pre_procecss')\n",
    "#from preprocessor import PreProcessor\n",
    "#preprocessor = PreProcessor(df, config_path='config-sample.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 시차 생성\n",
    "max_lag = 3\n",
    "\n",
    "# 시차 특성 생성\n",
    "data_with_lags = create_lag_features(df, columns_to_lag, max_lag)\n",
    "\n",
    "data_with_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이동 평균 (Moving Average) 특성 생성 함수 정의\n",
    "def create_moving_average_features(df, columns, windows):\n",
    "    df = df.copy()\n",
    "    for col in columns:\n",
    "        for window in windows:\n",
    "            df[f'{col}_ma_{window}'] = df[col].rolling(window=window).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이동 평균을 계산할 윈도우 크기 설정\n",
    "windows = [3,6,12]\n",
    "\n",
    "# 이동 평균 특성 생성\n",
    "data_with_moving_average = create_moving_average_features(data_with_lags, columns_to_lag, windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가적인 시계열 특성 생성 함수 정의\n",
    "def create_additional_ts_features(df, columns, windows):\n",
    "    df = df.copy()\n",
    "    for col in columns:\n",
    "        for window in windows:\n",
    "            # 이동 평균 편차 (Volatility)\n",
    "            df[f'{col}_std_{window}'] = df[col].rolling(window=window).std()\n",
    "            # 차분 (Difference)\n",
    "            df[f'{col}_diff_{window}'] = df[col] - df[col].shift(window)\n",
    "            # 지수 이동 평균 (EMA)\n",
    "            df[f'{col}_ema_{window}'] = df[col].ewm(span=window, adjust=False).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값 제거 함수 (시계열 특성에서 발생한 결측값만 제거)\n",
    "def remove_ts_related_missing_values(df, columns, max_lag):\n",
    "    # 시차(Lag) 및 시계열 특성으로 인한 결측값을 처리할 컬럼 정의\n",
    "    lagged_columns = [f'{col}_lag_{lag}' for col in columns for lag in range(1, max_lag + 1)]\n",
    "    moving_avg_columns = [f'{col}_ma_{window}' for col in columns for window in [3, 6, 12]]\n",
    "    volatility_columns = [f'{col}_std_{window}' for col in columns for window in [3, 6, 12]]\n",
    "    \n",
    "    # 해당 컬럼들에서 발생한 결측값만 제거\n",
    "    relevant_columns = lagged_columns + moving_avg_columns + volatility_columns\n",
    "    df_cleaned = df.dropna(subset=relevant_columns).reset_index(drop=True)\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가적인 시계열 특성 생성\n",
    "data_with_ts_features = create_additional_ts_features(data_with_moving_average, columns_to_lag, windows)\n",
    "\n",
    "# 최종 데이터셋에서 결측값 제거 (시계열 특성 생성으로 인한 결측값)\n",
    "data_final = remove_ts_related_missing_values(data_with_ts_features,columns_to_lag,max_lag)\n",
    "#data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터: 8722, test 데이터: 2792, 최종 데이터: 11514\n"
     ]
    }
   ],
   "source": [
    "_target = data_with_ts_features[\"target\"]\n",
    "\n",
    "# _type이 train인 데이터의 결측치만 삭제\n",
    "df1 = remove_ts_related_missing_values(data_with_ts_features[data_with_ts_features['_type']=='train'],columns_to_lag,max_lag)\n",
    "# _type이 test인 데이터는 결측치를 삭제하지 않고 그대로 유지\n",
    "df2 = data_with_ts_features[data_with_ts_features['_type']=='test'].ffill().assign(target=_target)\n",
    "\n",
    "# train과 test 데이터를 다시 합침\n",
    "final_data = pd.concat([df1, df2], axis=0).reset_index(drop=True)\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"train 데이터: {len(df1)}, test 데이터: {len(df2)}, 최종 데이터: {len(final_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "2.0    3652\n",
       "1.0    3531\n",
       "3.0     804\n",
       "0.0     735\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도: 0.7279633080120396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.29      0.45       594\n",
      "           1       0.73      0.79      0.76      2809\n",
      "           2       0.70      0.84      0.76      2932\n",
      "           3       0.95      0.34      0.50       642\n",
      "\n",
      "    accuracy                           0.73      6977\n",
      "   macro avg       0.83      0.57      0.62      6977\n",
      "weighted avg       0.76      0.73      0.71      6977\n",
      "\n",
      "검증 정확도: 0.4681948424068768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.12      0.21       141\n",
      "           1       0.47      0.51      0.49       722\n",
      "           2       0.47      0.58      0.52       720\n",
      "           3       0.26      0.07      0.12       162\n",
      "\n",
      "    accuracy                           0.47      1745\n",
      "   macro avg       0.48      0.32      0.33      1745\n",
      "weighted avg       0.47      0.47      0.44      1745\n",
      "\n",
      "교차 검증 평균 정확도: 0.4585053044540982\n"
     ]
    }
   ],
   "source": [
    "# XGBoost 모델 훈련 및 평가를 위해 데이터 분할\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# _type에 따라 train, test 분리\n",
    "train_df = final_data.loc[final_data[\"_type\"] == \"train\"].drop(columns=[\"_type\"])\n",
    "test_df = final_data.loc[final_data[\"_type\"] == \"test\"].drop(columns=[\"_type\"])\n",
    "\n",
    "# train_test_split 으로 valid set, train set 분리\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    train_df.drop([\"target\", \"ID\"], axis=1),\n",
    "    train_df[\"target\"].astype(int),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# XGBoost 모델 생성 및 학습\n",
    "xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    learning_rate = 0.05,\n",
    "    max_depth=5,\n",
    "    n_estimators=100,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42)\n",
    "\n",
    "# XGBoost 모델 훈련\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_train_pred = xgb_model.predict(x_train)\n",
    "y_valid_pred = xgb_model.predict(x_valid)\n",
    "\n",
    "# 성능 평가 (훈련)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_classification_rep = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# 성능 평가 (검증)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_pred)\n",
    "valid_classification_rep = classification_report(y_valid, y_valid_pred)\n",
    "\n",
    "print(f\"훈련 정확도: {train_accuracy}\")\n",
    "print(train_classification_rep)\n",
    "print(f\"검증 정확도: {valid_accuracy}\")\n",
    "print(valid_classification_rep)\n",
    "\n",
    "# 교차 검증\n",
    "scores = cross_val_score(xgb_model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"교차 검증 평균 정확도: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, SVMSMOTE\n",
    "\n",
    "def get_over_sampler(x_train, y_train, strategy='ADASYN', sampling_strategy='auto'):\n",
    "    if strategy == 'SMOTE':\n",
    "        sampler = SMOTE(sampling_strategy=sampling_strategy)\n",
    "    elif strategy == 'BorderlineSMOTE':\n",
    "        sampler = BorderlineSMOTE(sampling_strategy=sampling_strategy)\n",
    "    elif strategy == 'ADASYN':\n",
    "        sampler = ADASYN(sampling_strategy=sampling_strategy)\n",
    "    elif strategy == 'SVMSMOTE':\n",
    "        sampler = SVMSMOTE(sampling_strategy=sampling_strategy)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "\n",
    "    x_resampled, y_resampled = sampler.fit_resample(x_train, y_train)\n",
    "    return x_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도: 0.9843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1500\n",
      "           1       0.98      0.99      0.99      3500\n",
      "           2       0.98      0.99      0.98      3500\n",
      "           3       0.99      0.97      0.98      1500\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.99      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "검증 정확도: 0.439541547277937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.13      0.17       141\n",
      "           1       0.47      0.51      0.49       722\n",
      "           2       0.46      0.49      0.48       720\n",
      "           3       0.24      0.16      0.19       162\n",
      "\n",
      "    accuracy                           0.44      1745\n",
      "   macro avg       0.35      0.32      0.33      1745\n",
      "weighted avg       0.42      0.44      0.43      1745\n",
      "\n",
      "교차 검증 평균 정확도: 0.6012000000000001\n"
     ]
    }
   ],
   "source": [
    "# XGBoost 모델 훈련 및 평가를 위해 데이터 분할\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# _type에 따라 train, test 분리\n",
    "train_df = final_data.loc[final_data[\"_type\"] == \"train\"].drop(columns=[\"_type\"])\n",
    "train_df = train_df.ffill()\n",
    "test_df = final_data.loc[final_data[\"_type\"] == \"test\"].drop(columns=[\"_type\"])\n",
    "\n",
    "# train_test_split 으로 valid set, train set 분리\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    train_df.drop([\"target\", \"ID\"], axis=1),\n",
    "    train_df[\"target\"].astype(int),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "sampling_strategy = {0:1500, 1: 3500, 2:3500, 3:1500}\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy,random_state=42)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "# XGBoost 모델 생성 및 학습\n",
    "xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    learning_rate = 0.05,\n",
    "    max_depth=5,\n",
    "    n_estimators=500,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42)\n",
    "\n",
    "# XGBoost 모델 훈련\n",
    "xgb_model.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "# 예측\n",
    "y_train_pred = xgb_model.predict(x_train_resampled)\n",
    "y_valid_pred = xgb_model.predict(x_valid)\n",
    "\n",
    "# 성능 평가 (훈련)\n",
    "train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
    "train_classification_rep = classification_report(y_train_resampled, y_train_pred)\n",
    "\n",
    "# 성능 평가 (검증)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_pred)\n",
    "valid_classification_rep = classification_report(y_valid, y_valid_pred)\n",
    "\n",
    "print(f\"훈련 정확도: {train_accuracy}\")\n",
    "print(train_classification_rep)\n",
    "print(f\"검증 정확도: {valid_accuracy}\")\n",
    "print(valid_classification_rep)\n",
    "\n",
    "# 교차 검증\n",
    "scores = cross_val_score(xgb_model, x_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "print(f\"교차 검증 평균 정확도: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "1    3500\n",
      "2    3500\n",
      "0    1500\n",
      "3    1500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = xgb_model.predict(test_df.drop([\"target\", \"ID\"],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 03:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>2024-04-26 03:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>2024-04-26 04:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2789</th>\n",
       "      <td>2024-04-26 05:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>2024-04-26 06:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>2024-04-26 07:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID  target\n",
       "0     2024-01-01 00:00:00       1\n",
       "1     2024-01-01 01:00:00       1\n",
       "2     2024-01-01 02:00:00       1\n",
       "3     2024-01-01 03:00:00       2\n",
       "4     2024-01-01 04:00:00       1\n",
       "...                   ...     ...\n",
       "2787  2024-04-26 03:00:00       0\n",
       "2788  2024-04-26 04:00:00       0\n",
       "2789  2024-04-26 05:00:00       1\n",
       "2790  2024-04-26 06:00:00       0\n",
       "2791  2024-04-26 07:00:00       0\n",
       "\n",
       "[2792 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = submission_df.assign(target=pd.DataFrame(y_test_pred))\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    964\n",
       "2    913\n",
       "0    805\n",
       "3    110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"xgb_test3_lag.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
