{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from prophet import Prophet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# Code 경로 추가\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"\"))))\n",
    "print(sys.path[-1])\n",
    "pd.set_option('display.max_columns', None)  # 전체 열 출력하기\n",
    "pd.set_option('display.max_rows', None)  # 전체 행 출력하기"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 파일 호출\n",
    "data_path: str = \"../../data\"\n",
    "## raw.csv가 없는 경우 실행\n",
    "# from Code.dataset.merge_all import merge_all\n",
    "# df = merge_all(data_path)\n",
    "train_data: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"raw.csv\"))\n",
    "train_data = train_data.loc[train_data[\"_type\"] == \"train\"]\n",
    "sub: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\"))  # ID, target 열만 가진 데이터 미리 호출\n",
    "sub[\"Time\"] = sub.ID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cols = train_data.columns\n",
    "new_cols = []\n",
    "for col in cols:\n",
    "    if col in ['ID', 'target', '_type']:\n",
    "        new_cols.append(col)\n",
    "        continue\n",
    "    col = f\"{col}\".replace(\"hourly_\", \"\").split(\"_\", maxsplit=2)[2]\n",
    "    new_cols.append(col)\n",
    "\n",
    "train_data.columns = new_cols\n",
    "# 종가 및 거래량 컬럼 찾기\n",
    "new_cols = []\n",
    "for c in train_data.columns:\n",
    "    if c.find(\"close\") != -1 or c.find(\"volume\") != -1:\n",
    "        print(c)\n",
    "    if c.__contains__(\"all_exchange\") or c in ['ID', 'target', '_type'] or c.__contains__(\n",
    "            \"block\") or c.__contains__(\"difficulty\") or c.__contains__(\"supply\") or c.__contains__(\"fees\"):\n",
    "        new_cols.append(c)\n",
    "\n",
    "train_data = train_data[new_cols]\n",
    "rename_dict = {\n",
    "    \"all_exchange_spot_btc_usd_close\": \"target_closed\",\n",
    "    \"all_exchange_spot_btc_usd_volume\": \"target_volume\"\n",
    "}\n",
    "train_data.rename(columns=rename_dict, inplace=True)\n",
    "train_data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Closed(%) to Target(Class)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig: go.Figure = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    shared_xaxes=True,\n",
    "    subplot_titles=(\n",
    "        \"closed to target(%)\",\n",
    "        \"volume to target(%)\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "up_down_closed = 1 - (train_data[\"target_closed\"].shift(-1) / train_data[\"target_closed\"])\n",
    "up_down_volume = 1 - (train_data[\"target_volume\"].shift(-1) / train_data[\"target_volume\"])\n",
    "train_data.loc[:, \"up_down_closed\"] = up_down_closed\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=train_data[\"target\"], y=up_down_closed,\n",
    "               mode=\"markers\"), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Box(x=train_data[\"target\"], y=up_down_volume), row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Target\")\n",
    "fig.update_layout(title_text=\"Target statistics\", showlegend=False)\n",
    "fig.show()\n",
    "train_data[\"up_down_closed\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def closed_to_target(closed_series: pd.Series) -> float:\n",
    "    closed = closed_series.copy()\n",
    "    closed_future = closed_series.shift(-1)\n",
    "    _up_down_closed = 1 - (closed / closed_future)\n",
    "\n",
    "    def to_class(x: float):\n",
    "        if x <= -0.05:\n",
    "            return 0.0\n",
    "        elif x < 0:\n",
    "            return 1.0\n",
    "        elif x < 0.05:\n",
    "            return 2.0\n",
    "        else:\n",
    "            return 3.0\n",
    "\n",
    "    result = _up_down_closed.apply(to_class)\n",
    "    return result\n",
    "\n",
    "\n",
    "# closed_to_percent(train_data[\"target_closed\"])\n",
    "pd.concat(\n",
    "    [train_data[\"ID\"], train_data[\"target_closed\"], train_data[\"target_closed\"].shift(1), train_data[\"target\"],\n",
    "     closed_to_target(train_data[\"target_closed\"]), train_data[\"ID\"].shift(-1)],\n",
    "    axis=1,\n",
    "    ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_data.info()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_data.drop(columns=[\"all_exchange_open_interest\"], inplace=True)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_data.dropna().info()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import anderson, shapiro\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, RobustScaler\n",
    "\n",
    "# \n",
    "columns = train_data.columns.values.tolist()\n",
    "columns.remove(\"ID\")\n",
    "columns.remove(\"_type\")\n",
    "# \n",
    "train_df = train_data[columns].dropna().reset_index(drop=True)\n",
    "scaler_1 = RobustScaler()\n",
    "# # scaler_minmax.fit(train_data[columns])\n",
    "scaled_train_df = scaler_1.fit_transform(train_df)\n",
    "scaled_train_df = pd.DataFrame(scaled_train_df, columns=columns)\n",
    "\n",
    "scaler_2 = Normalizer()\n",
    "scaled_train_df = scaler_2.fit_transform(scaled_train_df)\n",
    "scaled_train_df = pd.DataFrame(scaled_train_df, columns=columns)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train_data[\"target_closed\"].plot()\n",
    "# scaled_train_test = (np.exp2(scaled_train_df[\"target_closed\"]))\n",
    "# scaled_train_test.plot(kind=\"bar\")\n",
    "norm_target = anderson(\n",
    "    scaled_train_df[\"target_closed\"])  #anderson(scaled_train_df)  #train_data[\"up_down_closed\"].dropna(), dist='norm')\n",
    "print(norm_target, \"\\n\", anderson(train_data[\"target_closed\"]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 양수 일때의 상관계수\n",
    "\n",
    "df_corr = scaled_train_df.corr()[\"up_down_closed\"]  #[\"up_down_closed\"]  #[\"target_closed\"]\n",
    "df_corr = df_corr[df_corr != 1]\n",
    "abs(df_corr).sort_values(ascending=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_corr = train_data.drop(columns=[\"ID\", \"_type\"]).corr()[\"up_down_closed\"]  #[\"up_down_closed\"]  #[\"target_closed\"]\n",
    "df_corr = df_corr[df_corr != 1]\n",
    "abs(df_corr).sort_values(ascending=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pred_len = 2792\n",
    "\n",
    "\n",
    "class ProphetAVG:\n",
    "    def __init__(self, scale1=0.01, scale2=0.1):  # changepoint 반영 비율\n",
    "        self.models = [\n",
    "            Prophet(seasonality_mode='additive', changepoint_range=1,\n",
    "                    changepoint_prior_scale=scale1),  # 기간 내 적은 changepoints 반영(trend에 강건)\n",
    "            Prophet(seasonality_mode='additive', changepoint_range=1,\n",
    "                    changepoint_prior_scale=scale2)  # 기간 내 많은 changepoints 반영(trend에 민감)\n",
    "        ]\n",
    "        self.forecasts = []\n",
    "        self.df = None\n",
    "\n",
    "    def fit(self, data):\n",
    "        for model in self.models:\n",
    "            model.fit(data)\n",
    "\n",
    "    def predict(self, periods=pred_len, freq='h'):\n",
    "        future_frames = [model.make_future_dataframe(periods=periods, freq=freq) for model in self.models]\n",
    "        forecasts = [model.predict(future) for model, future in zip(self.models, future_frames)]\n",
    "        # 두 모델의 평균 예측 생성\n",
    "        avg_forecast = pd.concat([forecast['yhat'] for forecast in forecasts], axis=1).mean(axis=1)\n",
    "        self.df = pd.DataFrame({\n",
    "            'Time': sub['Time'],\n",
    "            'Close': avg_forecast[-periods:].reset_index(drop=True)\n",
    "        })\n",
    "        return self.df\n",
    "\n",
    "    def plot(self):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(self.df['Time'], self.df['Close'], label='Prediction', marker='o', linestyle='-')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Close Price')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ma_train_df = train_data\n",
    "rename_dict = {\n",
    "    \"target_closed\": \"y\",\n",
    "    \"ID\": \"ds\"\n",
    "}\n",
    "ma_train_df.rename(columns=rename_dict, inplace=True)\n",
    "ma_train_df[\"Time\"] = ma_train_df[\"ds\"]\n",
    "longterm_model = ProphetAVG()\n",
    "longterm_model.fit(train_data)\n",
    "longterm_forecast = longterm_model.predict()\n",
    "# 안정화한 장기 예측 결과 plot\n",
    "longterm_model.plot()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## 6개월 학습모델\n",
    "midterm_train = ma_train_df[ma_train_df['ds'] >= '2023-03-29  12:00:00']\n",
    "\n",
    "midterm_model = ProphetAVG()\n",
    "midterm_model.fit(midterm_train)\n",
    "midterm_forecast = midterm_model.predict()\n",
    "\n",
    "## 3개월 학습모델\n",
    "shortterm_train = ma_train_df[ma_train_df['ds'] >= '2023-09-29  12:00:00']\n",
    "\n",
    "shortterm_model = ProphetAVG()\n",
    "shortterm_model.fit(shortterm_train)\n",
    "shortterm_forecast = shortterm_model.predict()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def ensemble_df():\n",
    "    weighted_pred = []\n",
    "\n",
    "    for idx in range(pred_len):\n",
    "        if idx < pred_len * 1 / 4:  # 0 ~ 25% 기간\n",
    "            weight = 1 - idx / pred_len * 4\n",
    "            weighted_sum = (shortterm_forecast['Close'][idx] * weight +\n",
    "                            midterm_forecast['Close'][idx] * (1 - weight) / 2 +\n",
    "                            longterm_forecast['Close'][idx] * (1 - weight) / 2)\n",
    "\n",
    "        elif idx < pred_len * 3 / 4:  # 25 ~ 75% 기간\n",
    "            weight = 0.5 - (idx - pred_len * 1 / 4) / (pred_len * 1 / 2) / 2\n",
    "            weighted_sum = (midterm_forecast['Close'][idx] * weight +\n",
    "                            longterm_forecast['Close'][idx] * (1 - weight))\n",
    "\n",
    "        else:  # 75% ~ 100% 기간\n",
    "            weighted_sum = longterm_forecast['Close'][idx]\n",
    "\n",
    "        weighted_pred.append(weighted_sum)\n",
    "\n",
    "    return pd.DataFrame({'Time': sub['Time'], 'Close': weighted_pred})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "forecast = ensemble_df()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(forecast['Time'], forecast['Close'], label='Prediction', marker='o', linestyle='-')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Close Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "forecast.columns = [\"ID\", \"target\"]\n",
    "forecast[\"target\"] = closed_to_target(forecast[\"target\"])\n",
    "forecast[\"target\"] = forecast[\"target\"].astype(int)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "forecast.to_csv(\"output.csv\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "forecast.groupby(by=[\"target\"]).count()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
